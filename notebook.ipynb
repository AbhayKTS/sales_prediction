{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "909fc657",
   "metadata": {},
   "source": [
    "# Campaign Sales Model Walkthrough\n",
    "This notebook rebuilds the linear regression model used in the project, step by step, using the advertising dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67472db",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "1. Load and inspect the dataset\n",
    "2. Prepare features and the target variable\n",
    "3. Split into training and validation sets\n",
    "4. Fit a closed-form linear regression (no external dependencies beyond NumPy/Pandas)\n",
    "5. Evaluate R² / RMSE / MAE\n",
    "6. Visualize predictions vs. actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f85640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style='darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dbdb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "DATA_PATH = Path('notebooks/data/Advertising And Sales.csv')\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f'Dataset not found at {DATA_PATH.resolve()}')\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f'Dataset shape: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3e1554",
   "metadata": {},
   "source": [
    "### Feature preparation\n",
    "We'll use TV, Radio, and Newspaper spend as predictors and Sales (in thousands of units) as the target. Missing rows are dropped for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fea7e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLS = ['TV', 'Radio', 'Newspaper']\n",
    "TARGET_COL = 'Sales'\n",
    "df = df.dropna(subset=FEATURE_COLS + [TARGET_COL]).reset_index(drop=True)\n",
    "X = df[FEATURE_COLS].values\n",
    "y = df[TARGET_COL].values\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e93951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation split (80/20, deterministic)\n",
    "RANDOM_STATE = 42\n",
    "train_df = df.sample(frac=0.8, random_state=RANDOM_STATE)\n",
    "test_df = df.drop(train_df.index)\n",
    "X_train, y_train = train_df[FEATURE_COLS].values, train_df[TARGET_COL].values\n",
    "X_test, y_test = test_df[FEATURE_COLS].values, test_df[TARGET_COL].values\n",
    "print(f'Train size: {len(train_df)} rows | Test size: {len(test_df)} rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85954719",
   "metadata": {},
   "source": [
    "### Closed-form linear regression\n",
    "We solve for θ = (XᵀX)⁻¹Xᵀy to match the original project pipeline without relying on scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f287a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_intercept(X):\n",
    "    ones = np.ones((X.shape[0], 1))\n",
    "    return np.hstack([ones, X])\n",
    "\n",
    "def fit_linear_regression(X, y):\n",
    "    X_design = add_intercept(X)\n",
    "    theta = np.linalg.pinv(X_design.T @ X_design) @ X_design.T @ y\n",
    "    intercept = float(theta[0])\n",
    "    coefs = theta[1:].astype(float)\n",
    "    return intercept, coefs\n",
    "\n",
    "intercept, coefs = fit_linear_regression(X_train, y_train)\n",
    "for name, coef in zip(FEATURE_COLS, coefs):\n",
    "    print(f'{name} coefficient: {coef:.4f}')\n",
    "print(f'Intercept: {intercept:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbb41ff",
   "metadata": {},
   "source": [
    "### Evaluation helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4525a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, intercept, coefs):\n",
    "    return intercept + X @ coefs\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    return 1 - ss_res / ss_tot\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "train_pred = predict(X_train, intercept, coefs)\n",
    "test_pred = predict(X_test, intercept, coefs)\n",
    "\n",
    "metrics = {\n",
    "    'train': {\n",
    "        'R2': r2_score(y_train, train_pred),\n",
    "        'RMSE': rmse(y_train, train_pred),\n",
    "        'MAE': mae(y_train, train_pred)\n",
    "    },\n",
    "    'test': {\n",
    "        'R2': r2_score(y_test, test_pred),\n",
    "        'RMSE': rmse(y_test, test_pred),\n",
    "        'MAE': mae(y_test, test_pred)\n",
    "    }\n",
    "}\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf28d66",
   "metadata": {},
   "source": [
    "### Predicted vs. actual (validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080483f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(x=y_test, y=test_pred, color='#00E0FF', edgecolor='black')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label='Ideal fit')\n",
    "plt.xlabel('Actual Sales (k units)')\n",
    "plt.ylabel('Predicted Sales (k units)')\n",
    "plt.title('Predicted vs Actual (Validation)')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f04a95",
   "metadata": {},
   "source": [
    "### Residual distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1247e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - test_pred\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(residuals, bins=15, kde=True, color='#14F195')\n",
    "plt.xlabel('Residual (Actual - Predicted)')\n",
    "plt.title('Validation Residuals Distribution')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
